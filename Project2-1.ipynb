{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Union, Dict, Tuple\n",
    "import pandas as pd\n",
    "from IPython.core.display import display\n",
    "from sklearn.metrics import label_ranking_average_precision_score, ndcg_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import normalize, minmax_scale\n",
    "\n",
    "def getRawData():\n",
    "    bug_report_raw=pd.read_pickle(\"Output/allBugReports.pickle\")\n",
    "    bug_report_raw = bug_report_raw[bug_report_raw['description'].notna()].reset_index()\n",
    "    display(bug_report_raw)\n",
    "\n",
    "    source_code_raw = pd.read_pickle(\"Output/allSourceCodes.pickle\")\n",
    "    source_code_raw = source_code_raw[source_code_raw['unprocessed_code'].notna()]\n",
    "    display(source_code_raw)\n",
    "    return bug_report_raw, source_code_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data\n",
    "\n",
    "First, we clean up the discrepancies between the bug report dataset and source code dataset. Here, we remove the missing files so that the data will represent a more accurate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filterBugReportsMissingFiles(bug_report_raw, source_code_raw):\n",
    "    source_file_names_dot_format=set(source_code_raw[\"filename\"].map(lambda fname:\"org\"+fname.partition(\"org\")[2].replace(\"\\\\\",\".\")).tolist())\n",
    "\n",
    "    # create copy of bug report dataframe\n",
    "    filter_missing_files = bug_report_raw.copy()\n",
    "\n",
    "    # return the filenames that appear in the source code dataframe only\n",
    "    for index, row in filter_missing_files.iterrows():\n",
    "        filter_missing_files.at[index, \"fix\"] = list(set(row['fix']).intersection(source_file_names_dot_format))\n",
    "\n",
    "    # filter out empty arrays\n",
    "    filter_missing_files = filter_missing_files[filter_missing_files.fix.str.len()>0]\n",
    "    return filter_missing_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we clean the textual data.  \n",
    "\n",
    "Snowball Stemmer is used since it is a more powerful stemmer than what is used by the research paper on IRFL (Porter Stemmer).\n",
    "  \n",
    "In addition to NLTK's stop words, Python and Java keywords have been removed to provide a better model for analysis. The Python keywords will come from a built-in library called \"keyword\", while Java language keywords will be extracted from a file provided by the original GitHub source found here: https://github.com/exatoa/Bench4BL/blob/master/scripts/languages.txt\n",
    "\n",
    "Camel case words such as setValue will be split into two words, \"set\" and \"Value\".\n",
    "\n",
    "All letters will be turned into lowercases so there would not be any distinction between \"Value\" and \"value\", for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keyword\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib.pyplot as plt \n",
    "import html\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "java_keywords = None\n",
    "with open('languages.txt', 'r') as file:\n",
    "    java_keywords = file.read().split('\\n')\n",
    "\n",
    "# set for o(1) lookup performance\n",
    "stop_words = set(list(ENGLISH_STOP_WORDS) + keyword.kwlist + java_keywords)\n",
    "\n",
    "def clean_text(text):\n",
    "    # This is to remove the double html encodings such as &amp;apos; into simply &apos;.\n",
    "    # This html encoding is easier to convert into punctuation or special characters for removal.\n",
    "    text = text.replace(\"&amp;\", '&')\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # split words and return them if it is not in the stop words list\n",
    "    def getIndividualWords(all_text:str) ->Iterable[str]:\n",
    "        # this regex splits apart camel case variables.\n",
    "        # first half of | handles cases which are traditionally camel cased, or are just lower case.\n",
    "        # second half of | handles cases where its all capital letters, ie a variable named VARIABLE\n",
    "        # this also implicitly gets rid of any punctuation and any whitespace. This is because the regex\n",
    "        # skips over any non-letter characters\n",
    "        for word in re.findall('[A-Z]*[a-z]+|[A-Z]{2,}', all_text):\n",
    "            word_lower=word.lower()\n",
    "            if word_lower not in stop_words:\n",
    "                yield stemmer.stem(word_lower)\n",
    "\n",
    "    text=' '.join(getIndividualWords(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first two tables show the original dataset, while the next two show the newly processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fix</th>\n",
       "      <th>text</th>\n",
       "      <th>fixdate</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>project</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217</td>\n",
       "      <td>[org.apache.commons.collections.map.flat3map.j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-18 22:02:11</td>\n",
       "      <td>Flat3Map.Entry.setValue() overwrites other Ent...</td>\n",
       "      <td>Flat3Map&amp;amp;apos;s Entry objects will overwri...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214</td>\n",
       "      <td>[org.apache.commons.collections.testextendedpr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-18 22:44:33</td>\n",
       "      <td>ExtendedProperties - field include should be n...</td>\n",
       "      <td>The field \"include\" in ExtendedProperties is c...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222</td>\n",
       "      <td>[org.apache.commons.collections.testlistutils....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-18 19:01:22</td>\n",
       "      <td>CollectionUtils removeAll is actually retainAll</td>\n",
       "      <td>The removeAll(Collection collection, Collectio...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>261</td>\n",
       "      <td>[org.apache.commons.collections.map.flat3map.j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-20 14:11:54</td>\n",
       "      <td>Flat3Map.remove() does not return the correct ...</td>\n",
       "      <td>final Flat3Map m = new Flat3Map();\\n  ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264</td>\n",
       "      <td>[org.apache.commons.collections.fasttreemap.java]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-31 09:39:59</td>\n",
       "      <td>FastTreeMap forgets the comparator</td>\n",
       "      <td>In line 359 and 582 of the current 3.2 release...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>692</td>\n",
       "      <td>[org.wildfly.security.auth.realm.legacypropert...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-02 09:35:48</td>\n",
       "      <td>Add tests for special chars in LegacyPropertie...</td>\n",
       "      <td>Add tests for issue https://issues.jboss.org/b...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>691</td>\n",
       "      <td>[org.wildfly.security.auth.realm.legacypropert...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-02 09:36:13</td>\n",
       "      <td>Elytron properties-realm is not compatible wit...</td>\n",
       "      <td>When users properties file (e.g. mgmt-users.pr...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>637</td>\n",
       "      <td>[org.wildfly.security.auth.server.serverauthen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-03 15:03:29</td>\n",
       "      <td>No log messages comming from Elytron - permiss...</td>\n",
       "      <td>Elytron is missing any log messages related to...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>757</td>\n",
       "      <td>[org.wildfly.security.ssl.sslauthenticationtes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-21 09:24:47</td>\n",
       "      <td>Don&amp;apos;t use String toUpperCase/toLowerCase ...</td>\n",
       "      <td>The String.toUpperCase() and String.toLowerCas...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>808</td>\n",
       "      <td>[org.wildfly.security.auth.client.elytronxmlpa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-02 17:08:15</td>\n",
       "      <td>XML Parsing Deferred into Function</td>\n",
       "      <td>e.g.\\n\\n\\n\\n\\n\\n\\n                    case \"cl...</td>\n",
       "      <td>ELY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1790 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                                fix text  \\\n",
       "0     217  [org.apache.commons.collections.map.flat3map.j...  NaN   \n",
       "1     214  [org.apache.commons.collections.testextendedpr...  NaN   \n",
       "2     222  [org.apache.commons.collections.testlistutils....  NaN   \n",
       "3     261  [org.apache.commons.collections.map.flat3map.j...  NaN   \n",
       "4     264  [org.apache.commons.collections.fasttreemap.java]  NaN   \n",
       "...   ...                                                ...  ...   \n",
       "1785  692  [org.wildfly.security.auth.realm.legacypropert...  NaN   \n",
       "1786  691  [org.wildfly.security.auth.realm.legacypropert...  NaN   \n",
       "1787  637  [org.wildfly.security.auth.server.serverauthen...  NaN   \n",
       "1788  757  [org.wildfly.security.ssl.sslauthenticationtes...  NaN   \n",
       "1789  808  [org.wildfly.security.auth.client.elytronxmlpa...  NaN   \n",
       "\n",
       "                  fixdate                                            summary  \\\n",
       "0     2006-07-18 22:02:11  Flat3Map.Entry.setValue() overwrites other Ent...   \n",
       "1     2006-07-18 22:44:33  ExtendedProperties - field include should be n...   \n",
       "2     2006-08-18 19:01:22    CollectionUtils removeAll is actually retainAll   \n",
       "3     2007-08-20 14:11:54  Flat3Map.remove() does not return the correct ...   \n",
       "4     2007-08-31 09:39:59                 FastTreeMap forgets the comparator   \n",
       "...                   ...                                                ...   \n",
       "1785  2016-11-02 09:35:48  Add tests for special chars in LegacyPropertie...   \n",
       "1786  2016-11-02 09:36:13  Elytron properties-realm is not compatible wit...   \n",
       "1787  2016-11-03 15:03:29  No log messages comming from Elytron - permiss...   \n",
       "1788  2016-11-21 09:24:47  Don&apos;t use String toUpperCase/toLowerCase ...   \n",
       "1789  2016-12-02 17:08:15                 XML Parsing Deferred into Function   \n",
       "\n",
       "                                            description      project  \\\n",
       "0     Flat3Map&amp;apos;s Entry objects will overwri...  COLLECTIONS   \n",
       "1     The field \"include\" in ExtendedProperties is c...  COLLECTIONS   \n",
       "2     The removeAll(Collection collection, Collectio...  COLLECTIONS   \n",
       "3             final Flat3Map m = new Flat3Map();\\n  ...  COLLECTIONS   \n",
       "4     In line 359 and 582 of the current 3.2 release...  COLLECTIONS   \n",
       "...                                                 ...          ...   \n",
       "1785  Add tests for issue https://issues.jboss.org/b...          ELY   \n",
       "1786  When users properties file (e.g. mgmt-users.pr...          ELY   \n",
       "1787  Elytron is missing any log messages related to...          ELY   \n",
       "1788  The String.toUpperCase() and String.toLowerCas...          ELY   \n",
       "1789  e.g.\\n\\n\\n\\n\\n\\n\\n                    case \"cl...          ELY   \n",
       "\n",
       "      average_precision  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "...                 ...  \n",
       "1785                0.0  \n",
       "1786                0.0  \n",
       "1787                0.0  \n",
       "1788                0.0  \n",
       "1789                0.0  \n",
       "\n",
       "[1790 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>unprocessed_code</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>\\gitrepo\\src\\main\\java\\org\\wildfly\\security\\ut...</td>\n",
       "      <td>/*\\n * JBoss, Home of Professional Open Source...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>\\gitrepo\\src\\main\\java\\org\\wildfly\\security\\_p...</td>\n",
       "      <td>/*\\n * JBoss, Home of Professional Open Source...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>\\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ma...</td>\n",
       "      <td>/*\\n * JBoss, Home of Professional Open Source...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>\\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ma...</td>\n",
       "      <td>/*\\n * JBoss, Home of Professional Open Source...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>\\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ss...</td>\n",
       "      <td>/*\\n * JBoss, Home of Professional Open Source...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10461 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  \\\n",
       "0   \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "1   \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "2   \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "3   \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "4   \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "..                                                ...   \n",
       "63  \\gitrepo\\src\\main\\java\\org\\wildfly\\security\\ut...   \n",
       "64  \\gitrepo\\src\\main\\java\\org\\wildfly\\security\\_p...   \n",
       "65  \\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ma...   \n",
       "66  \\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ma...   \n",
       "67  \\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ss...   \n",
       "\n",
       "                                     unprocessed_code      project  \n",
       "0   /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "1   /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "2   /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "3   /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "4   /*\\n *  Licensed to the Apache Software Founda...  COLLECTIONS  \n",
       "..                                                ...          ...  \n",
       "63  /*\\n * JBoss, Home of Professional Open Source...          ELY  \n",
       "64  /*\\n * JBoss, Home of Professional Open Source...          ELY  \n",
       "65  /*\\n * JBoss, Home of Professional Open Source...          ELY  \n",
       "66  /*\\n * JBoss, Home of Professional Open Source...          ELY  \n",
       "67  /*\\n * JBoss, Home of Professional Open Source...          ELY  \n",
       "\n",
       "[10461 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fix</th>\n",
       "      <th>processed_all</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[org.apache.commons.collections.map.flat3map.j...</td>\n",
       "      <td>flat map s entri object overwrit entri s valu ...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[org.apache.commons.collections.extendedproper...</td>\n",
       "      <td>field includ extend properti current instanc s...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[org.apache.commons.collections.collectionutil...</td>\n",
       "      <td>remov collect collect collect remov method cal...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[org.apache.commons.collections.map.flat3map.j...</td>\n",
       "      <td>flat map m flat map m integ integ m integ inte...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[org.apache.commons.collections.fasttreemap.java]</td>\n",
       "      <td>line current releas replac map tree map map tr...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>[org.wildfly.security.manager.wildflysecuritym...</td>\n",
       "      <td>infinit loop elytron permiss collect read reso...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>[org.wildfly.security.ssl.ciphersuiteselector....</td>\n",
       "      <td>cipher suit avail handshak https undertow list...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>[org.wildfly.security._private.elytronmessages...</td>\n",
       "      <td>elytron miss log messag relat group assign log...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>[org.wildfly.security.ssl.protocol.java]</td>\n",
       "      <td>protocol type list descript enabl protocol exp...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>[org.wildfly.security._private.elytronmessages...</td>\n",
       "      <td>elytron miss log messag relat permiss assign l...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1402 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    fix  \\\n",
       "0     [org.apache.commons.collections.map.flat3map.j...   \n",
       "1     [org.apache.commons.collections.extendedproper...   \n",
       "2     [org.apache.commons.collections.collectionutil...   \n",
       "3     [org.apache.commons.collections.map.flat3map.j...   \n",
       "4     [org.apache.commons.collections.fasttreemap.java]   \n",
       "...                                                 ...   \n",
       "1770  [org.wildfly.security.manager.wildflysecuritym...   \n",
       "1771  [org.wildfly.security.ssl.ciphersuiteselector....   \n",
       "1783  [org.wildfly.security._private.elytronmessages...   \n",
       "1784           [org.wildfly.security.ssl.protocol.java]   \n",
       "1787  [org.wildfly.security._private.elytronmessages...   \n",
       "\n",
       "                                          processed_all      project  \n",
       "0     flat map s entri object overwrit entri s valu ...  COLLECTIONS  \n",
       "1     field includ extend properti current instanc s...  COLLECTIONS  \n",
       "2     remov collect collect collect remov method cal...  COLLECTIONS  \n",
       "3     flat map m flat map m integ integ m integ inte...  COLLECTIONS  \n",
       "4     line current releas replac map tree map map tr...  COLLECTIONS  \n",
       "...                                                 ...          ...  \n",
       "1770  infinit loop elytron permiss collect read reso...          ELY  \n",
       "1771  cipher suit avail handshak https undertow list...          ELY  \n",
       "1783  elytron miss log messag relat group assign log...          ELY  \n",
       "1784  protocol type list descript enabl protocol exp...          ELY  \n",
       "1787  elytron miss log messag relat permiss assign l...          ELY  \n",
       "\n",
       "[1402 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>processed_code</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>licens apach softwar foundat asf contributor l...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>licens apach softwar foundat asf contributor l...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>licens apach softwar foundat asf contributor l...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>licens apach softwar foundat asf contributor l...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\gitrepo\\src\\java\\org\\apache\\commons\\collectio...</td>\n",
       "      <td>licens apach softwar foundat asf contributor l...</td>\n",
       "      <td>COLLECTIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>\\gitrepo\\src\\main\\java\\org\\wildfly\\security\\ut...</td>\n",
       "      <td>jboss home profession open sourc copyright red...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>\\gitrepo\\src\\main\\java\\org\\wildfly\\security\\_p...</td>\n",
       "      <td>jboss home profession open sourc copyright red...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>\\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ma...</td>\n",
       "      <td>jboss home profession open sourc copyright red...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>\\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ma...</td>\n",
       "      <td>jboss home profession open sourc copyright red...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>\\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ss...</td>\n",
       "      <td>jboss home profession open sourc copyright red...</td>\n",
       "      <td>ELY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10461 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  \\\n",
       "0   \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "1   \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "2   \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "3   \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "4   \\gitrepo\\src\\java\\org\\apache\\commons\\collectio...   \n",
       "..                                                ...   \n",
       "63  \\gitrepo\\src\\main\\java\\org\\wildfly\\security\\ut...   \n",
       "64  \\gitrepo\\src\\main\\java\\org\\wildfly\\security\\_p...   \n",
       "65  \\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ma...   \n",
       "66  \\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ma...   \n",
       "67  \\gitrepo\\src\\test\\java\\org\\wildfly\\security\\ss...   \n",
       "\n",
       "                                       processed_code      project  \n",
       "0   licens apach softwar foundat asf contributor l...  COLLECTIONS  \n",
       "1   licens apach softwar foundat asf contributor l...  COLLECTIONS  \n",
       "2   licens apach softwar foundat asf contributor l...  COLLECTIONS  \n",
       "3   licens apach softwar foundat asf contributor l...  COLLECTIONS  \n",
       "4   licens apach softwar foundat asf contributor l...  COLLECTIONS  \n",
       "..                                                ...          ...  \n",
       "63  jboss home profession open sourc copyright red...          ELY  \n",
       "64  jboss home profession open sourc copyright red...          ELY  \n",
       "65  jboss home profession open sourc copyright red...          ELY  \n",
       "66  jboss home profession open sourc copyright red...          ELY  \n",
       "67  jboss home profession open sourc copyright red...          ELY  \n",
       "\n",
       "[10461 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getProcessedData()->Tuple[Dict[str,pd.DataFrame],Dict[str,pd.DataFrame]]:\n",
    "    bug_report_raw,source_code_raw=getRawData()\n",
    "    filter_missing_files=filterBugReportsMissingFiles(bug_report_raw,source_code_raw)\n",
    "    filter_missing_files[\"processed_description\"]=filter_missing_files[\"description\"].map(clean_text)\n",
    "    filter_missing_files[\"processed_summary\"]=filter_missing_files[\"summary\"].map(clean_text)\n",
    "    filter_missing_files[\"processed_all\"]=filter_missing_files[\"processed_description\"] + filter_missing_files[\"processed_summary\"]\n",
    "    filter_missing_files=filter_missing_files[[\"fix\",\"processed_all\",\"project\"]]\n",
    "    display(filter_missing_files)\n",
    "    source_code_raw[\"processed_code\"]=source_code_raw[\"unprocessed_code\"].map(clean_text)\n",
    "    source_code_raw=source_code_raw[[\"filename\",\"processed_code\",\"project\"]]\n",
    "    display(source_code_raw)\n",
    "\n",
    "    valuesByNameDict={}\n",
    "    grouped_code=source_code_raw.groupby([\"project\"])\n",
    "    for project,files in filter_missing_files.groupby([\"project\"]):\n",
    "        valuesByNameDict[project]=files, grouped_code.get_group(project)\n",
    "    return valuesByNameDict\n",
    "\n",
    "bugReportAndCodeByProject=getProcessedData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Analyzing the Data\n",
    "After processing the data in the files, creating a label matrix is the next step. Each row of this matrix is for a bug report, and each column represents a source code file. A value of 1 is assigned to a cell if the file was changed to fix the bug. On the other hand, the value would be 0 if the file did not need to be changed to fix the bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "def getLabelsForBugReport()->Dict[str,np.ndarray]:\n",
    "    def getLabelsForProject(processed_bug_report, processed_source_code):\n",
    "        source_file_names_dot_format=processed_source_code[\"filename\"].map(lambda fname:\"org\"+fname.partition(\"org\")[2].replace(\"\\\\\",\".\"))\n",
    "\n",
    "        fileToIndex={}\n",
    "        for idx,value in enumerate(source_file_names_dot_format.values):\n",
    "            fileToIndex[value]=idx\n",
    "        num_files=len(source_file_names_dot_format)\n",
    "        num_bug_reports=len(processed_bug_report[\"fix\"])\n",
    "        matrix=lil_matrix((num_bug_reports,num_files))\n",
    "        for idx,file_names in enumerate(processed_bug_report[\"fix\"]):\n",
    "            for file_name in list(file_names):\n",
    "                try:\n",
    "                    matrix[idx,fileToIndex[file_name]]=1\n",
    "                except KeyError:\n",
    "                    # note, there are many files which were 'fixes' in bug reports, but where not in the tar files given on d2l.\n",
    "                    # we would assume then that the tar files posted on d2l were probably missing some source files (our theory\n",
    "                    # is the source code is from an older version of the software)\n",
    "                    pass\n",
    "        return matrix.toarray().astype(dtype=np.byte)\n",
    "    return {project:(bug_rep,src_code, getLabelsForProject(bug_rep,src_code)) for project,(bug_rep,src_code) in bugReportAndCodeByProject.items()}\n",
    "\n",
    "\n",
    "bugReportsCodeAndLabelsByProject=getLabelsForBugReport()\n",
    "display(bugReportsCodeAndLabelsByProject[\"COLLECTIONS\"][2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1\n",
    "In this section, we actually call our Method 1. In this method, we essentially have a basic implementation of the direct comparison section of BugLocator. \n",
    "\n",
    "Here, we directly compare the similarity of the bug report with the source code to see common terminology. For instance, if the bug report has the word 'view' in it, then it would weigh bug reports with the word 'view' in it more highly.\n",
    "\n",
    "To implement this aproach, we essentialy followed 3 steps:\n",
    "\n",
    "1. Create a TF-IDF vectroizer and fit it using all processed source files. Additionally, transform each source file. This would create the 'index' of our search.\n",
    "2. Transform the individual bug reports, using the TF-IDF vectorizer. Each word in the queried bug report would be weighed with respect to their frequency in the source code files (using the TFidf formula).\n",
    "3. The final probabilities are determined by the cosine similarity betwen each bug report output, and each soure file output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05614457, 0.07819238, 0.00728583, ..., 0.20191039, 0.12999105,\n",
       "        0.13608874],\n",
       "       [0.01058596, 0.03306154, 0.00842486, ..., 0.03143308, 0.02774896,\n",
       "        0.0282093 ],\n",
       "       [0.09154111, 0.16977882, 0.01113912, ..., 0.0330833 , 0.09188262,\n",
       "        0.0810769 ],\n",
       "       ...,\n",
       "       [0.04604789, 0.11243427, 0.02245275, ..., 0.05446629, 0.09667198,\n",
       "        0.11142991],\n",
       "       [0.04327248, 0.19574574, 0.0126602 , ..., 0.15218994, 0.17625421,\n",
       "        0.16115914],\n",
       "       [0.06166729, 0.23682712, 0.00558208, ..., 0.21829094, 0.21822892,\n",
       "        0.22592147]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gensim.models import LsiModel\n",
    "from gensim import similarities\n",
    "from gensim.test.utils import common_corpus\n",
    "\n",
    "def evaluateProject(processed_bug_report, processed_source_code, labels):\n",
    "\n",
    "    method1_vectorizer=TfidfVectorizer()\n",
    "    method1_code_vector=method1_vectorizer.fit_transform(processed_source_code[\"processed_code\"].to_numpy())\n",
    "    def method1(bug_report):\n",
    "        query_vector=method1_vectorizer.transform(bug_report[\"processed_all\"].to_numpy())\n",
    "        result = cosine_similarity(query_vector,method1_code_vector).astype(dtype=np.float32)\n",
    "        return result\n",
    "\n",
    "    similarities1=method1(processed_bug_report)\n",
    "\n",
    "    class Method2Evaluator:\n",
    "        def __init__(self,alpha=0.5):\n",
    "            self.alpha=alpha\n",
    "            self.bug_report_labels:Union[np.ndarray,None]=None\n",
    "            self.tfidf:Union[TfidfVectorizer,None]=None\n",
    "            self.bug_report_vector:Union[np.ndarray,None]=None\n",
    "\n",
    "        def get_params(self,**kwargs):\n",
    "            return {\"alpha\":self.alpha}\n",
    "\n",
    "        def set_params(self,alpha):\n",
    "            self.alpha=alpha\n",
    "\n",
    "\n",
    "        def fit(self, X:pd.DataFrame, y:np.ndarray):\n",
    "            self.bug_report_labels=y\n",
    "            self.tfidf=TfidfVectorizer()\n",
    "            self.bug_report_vector=self.tfidf.fit_transform(X[\"processed_all\"].to_numpy())\n",
    "\n",
    "        def getIndirectRelevancy(self,X:pd.DataFrame):\n",
    "            query_vector=self.tfidf.transform(X[\"processed_all\"].to_numpy())\n",
    "            similarity_between_bug_reports = cosine_similarity(query_vector,self.bug_report_vector).astype(dtype=np.float32)\n",
    "            ni=self.bug_report_labels.sum(1)\n",
    "            label_values_per_bug_report=(similarity_between_bug_reports/ni)\n",
    "            indirect=label_values_per_bug_report.dot(self.bug_report_labels)\n",
    "            min_maxed=minmax_scale(indirect,axis=1).astype(np.float32)\n",
    "            return min_maxed\n",
    "\n",
    "\n",
    "        def predict(self,X:pd.DataFrame)->np.ndarray:\n",
    "            indirect_relevancy=self.getIndirectRelevancy(X)\n",
    "            direct_relevancy=method1(X)\n",
    "            return (1-self.alpha)*direct_relevancy+self.alpha*indirect_relevancy\n",
    "\n",
    "    similarities2=cross_val_predict(Method2Evaluator(alpha=0.25),processed_bug_report,labels,cv=3)\n",
    "\n",
    "\n",
    "\n",
    "    class Method3Evaluator:\n",
    "        def __init__(self):\n",
    "            self.bug_report_labels:Union[np.ndarray,None]=None\n",
    "            self.tfidf:Union[TfidfVectorizer,None]=None\n",
    "            self.bug_report_vector:Union[np.ndarray,None]=None\n",
    "    \n",
    "        def get_params(self,**kwargs):\n",
    "            return {}\n",
    "    \n",
    "        def set_params(self):\n",
    "            pass\n",
    "    \n",
    "        def fit(self, X:pd.DataFrame, y:np.ndarray):\n",
    "            self.bug_report_labels=y\n",
    "            self.tfidf=TfidfVectorizer()\n",
    "            self.bug_report_vector=self.tfidf.fit_transform(X[\"processed_all\"].to_numpy())\n",
    "    \n",
    "            print(\"TFIDF:\", self.tfidf)\n",
    "            print(\"BUG_VECTOR:\", self.bug_report_vector)\n",
    "            print(\"BUG_VECTOR:\", type(self.bug_report_vector[1]))\n",
    "            print(common_corpus)\n",
    "            self.lsi = LsiModel(corpus = self.bug_report_vector.indices)\n",
    "            print(\"fit\")\n",
    "            pass\n",
    "    \n",
    "        def predict(self,X:pd.DataFrame)->np.ndarray:\n",
    "            return np.zeros((X.shape[0],similarities1.shape[1])).astype(np.float32)\n",
    "    \n",
    "    similarities3=cross_val_predict(Method3Evaluator(),processed_bug_report,labels)\n",
    "    similarities3\n",
    "\n",
    "project_similarities={project: evaluateProject(bug_rep, src_code, lbls)\n",
    "                      for project, (bug_rep,src_code, lbls) in bugReportsCodeAndLabelsByProject.items()}\n",
    "\n",
    "display(project_similarities[\"COLLECTIONS\"][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "To score our methodology, we used 3 different rankings:\n",
    "1. Mean Reciprocal Rank (MRR)\n",
    "2. Mean Average Precision (MAP)\n",
    "3. Normalized Discounted Cumulative Gain (NDCG)\n",
    "\n",
    "Each of these methodologies have their own pros and cons, which will be explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Mean Reciprocal Rank (MRR)\n",
    "\n",
    "Out of the three rankings listed above, MRR is the simplest and uses binary relevance metrics. The general algorithm of MRR is as follows:\n",
    "\n",
    "1. Create list of recommendations\n",
    "2. Rank the first relevant recommendation\n",
    "3. Compute the reciprocal rank\n",
    "\n",
    "To implement the MRR algorithm, we first filter out the input labels to only include the label with the maximum similarity. Every other label is set to 0. We then call the label_ranking_average_precision_score, using these filtered input labels. \n",
    "\n",
    "While this method is simple and easy to interpret, it equally weighs lists regardless if it has one relevant item or multiple relevant items.\n",
    "\n",
    "This methodology is identical to MRR as label_ranking_average_precision_score will be used. However, this is only true for  when there is a single input label. This is due to how the MRR algorithm only accounts for the highest ranked label. This is due to how the MRR algorithm only accounts for the highest ranked label. (source: https://medium.com/swlh/rank-aware-recsys-evaluation-metrics-5191bba16832)\n",
    "\n",
    "See  https://scikit-learn.org/stable/modules/model_evaluation.html#label-ranking-average-precision for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getMrrValue(denseLabels:np.ndarray, similarities:np.ndarray):\n",
    "    # first, create a version of the labels which only has the maximum label value.\n",
    "    similarities_with_labels=denseLabels*similarities\n",
    "    max_valued_label_indexes=np.argmax(similarities_with_labels,axis=1)\n",
    "    max_similar_labels=np.zeros_like(similarities_with_labels,dtype=np.byte)\n",
    "    max_similar_labels[np.arange(len(similarities_with_labels)),max_valued_label_indexes]=1\n",
    "\n",
    "    # then simply call label_ranking_average_precision_score, but only with the maximum labels.\n",
    "    # this will make it equivalent to mrr, according to sklearns documentation.\n",
    "    # see https://scikit-learn.org/stable/modules/model_evaluation.html#label-ranking-average-precision\n",
    "    return label_ranking_average_precision_score(max_similar_labels,similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Mean Average Precision (MAP)\n",
    "\n",
    "This method of evaluation takes the mean value of average precision values across all bug reports. The algorithm of this method is as follows (source: https://medium.com/swlh/rank-aware-recsys-evaluation-metrics-5191bba16832):\n",
    "\n",
    "For each user:\n",
    "- for each relevant item:\n",
    "    - compute precision of the list of that item\n",
    "- average the precisions of each sub-list\n",
    "\n",
    "This method weighs lists more reasonably, where more weight is given to errors that appear early in a recommended list. However, this is not suitable for fine-grained numerical ratings as it cannot extract any more info on the errors.\n",
    "\n",
    "To implement this, we simply used scikit-learn's label_ranking_average_precision_score method for the whole matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getMAPValue(denseLabels:np.ndarray,similarities:np.ndarray):\n",
    "    # simply call sklearns label_ranking_average_precision_score\n",
    "    # while they are explained differently, and use different terminology in their explanations,\n",
    "    # they are mathematically equivalent.\n",
    "    return label_ranking_average_precision_score(denseLabels,similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Normalized Discounted Cumulative Gain (NDCG)\n",
    "\n",
    "This metric is similar to MAP, wherein they both highly value relevant documents within recommended lists. The difference, however, is that NDCG has finer tuning for evaluating the list. As such, it knows that some items in the list are more relevant than others.\n",
    "\n",
    "As NDCG is a slightly more complex version of MAP, it is able to evaluate the position of ranked items better. \n",
    "\n",
    "To implement NDCG, we simply used scikil-learns ndcg_score (source: https://medium.com/swlh/rank-aware-recsys-evaluation-metrics-5191bba16832)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def getNDCGValue(denseLabels:np.ndarray,similarities:np.ndarray,num_considered=None):\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ndcg_score.html\n",
    "    return ndcg_score(denseLabels,similarities,k=num_considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mrr method1</th>\n",
       "      <th>mrr method2</th>\n",
       "      <th>mrr method3</th>\n",
       "      <th>map method1</th>\n",
       "      <th>map method2</th>\n",
       "      <th>map method3</th>\n",
       "      <th>NDCG method1</th>\n",
       "      <th>NDCG method2</th>\n",
       "      <th>NDCG method3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COLLECTIONS</th>\n",
       "      <td>0.611127</td>\n",
       "      <td>0.691181</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.506081</td>\n",
       "      <td>0.631861</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.736168</td>\n",
       "      <td>0.178958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONFIGURATION</th>\n",
       "      <td>0.512063</td>\n",
       "      <td>0.618102</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.379753</td>\n",
       "      <td>0.476717</td>\n",
       "      <td>0.011793</td>\n",
       "      <td>0.565068</td>\n",
       "      <td>0.644081</td>\n",
       "      <td>0.221910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATACMNS</th>\n",
       "      <td>0.495781</td>\n",
       "      <td>0.505893</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.399387</td>\n",
       "      <td>0.434572</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.565246</td>\n",
       "      <td>0.591686</td>\n",
       "      <td>0.179812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATAMONGO</th>\n",
       "      <td>0.344297</td>\n",
       "      <td>0.499480</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.255784</td>\n",
       "      <td>0.409134</td>\n",
       "      <td>0.006628</td>\n",
       "      <td>0.450049</td>\n",
       "      <td>0.579720</td>\n",
       "      <td>0.192093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATAREST</th>\n",
       "      <td>0.440216</td>\n",
       "      <td>0.534577</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.287949</td>\n",
       "      <td>0.379916</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>0.496861</td>\n",
       "      <td>0.576070</td>\n",
       "      <td>0.216743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELY</th>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.691837</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.564286</td>\n",
       "      <td>0.691837</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.673030</td>\n",
       "      <td>0.767301</td>\n",
       "      <td>0.242035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IO</th>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.775397</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.692353</td>\n",
       "      <td>0.735752</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0.783384</td>\n",
       "      <td>0.815925</td>\n",
       "      <td>0.254309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANG</th>\n",
       "      <td>0.662439</td>\n",
       "      <td>0.737022</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.611231</td>\n",
       "      <td>0.688487</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.721918</td>\n",
       "      <td>0.782246</td>\n",
       "      <td>0.197785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDAP</th>\n",
       "      <td>0.393211</td>\n",
       "      <td>0.590794</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.310105</td>\n",
       "      <td>0.446406</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>0.491315</td>\n",
       "      <td>0.615002</td>\n",
       "      <td>0.175887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEC</th>\n",
       "      <td>0.436858</td>\n",
       "      <td>0.377706</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.339469</td>\n",
       "      <td>0.303046</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.511650</td>\n",
       "      <td>0.479949</td>\n",
       "      <td>0.142977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOCIALFB</th>\n",
       "      <td>0.514705</td>\n",
       "      <td>0.484879</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>0.343802</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>0.578589</td>\n",
       "      <td>0.543406</td>\n",
       "      <td>0.207597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPR</th>\n",
       "      <td>0.204833</td>\n",
       "      <td>0.296062</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.120518</td>\n",
       "      <td>0.196923</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.317334</td>\n",
       "      <td>0.390757</td>\n",
       "      <td>0.132376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mrr method1  mrr method2  mrr method3  map method1  \\\n",
       "COLLECTIONS       0.611127     0.691181     0.002101     0.506081   \n",
       "CONFIGURATION     0.512063     0.618102     0.004464     0.379753   \n",
       "DATACMNS          0.495781     0.505893     0.001812     0.399387   \n",
       "DATAMONGO         0.344297     0.499480     0.002874     0.255784   \n",
       "DATAREST          0.440216     0.534577     0.002874     0.287949   \n",
       "ELY               0.552381     0.691837     0.014706     0.564286   \n",
       "IO                0.747021     0.775397     0.012346     0.692353   \n",
       "LANG              0.662439     0.737022     0.004049     0.611231   \n",
       "LDAP              0.393211     0.590794     0.001767     0.310105   \n",
       "SEC               0.436858     0.377706     0.000714     0.339469   \n",
       "SOCIALFB          0.514705     0.484879     0.003953     0.399675   \n",
       "SPR               0.204833     0.296062     0.000170     0.120518   \n",
       "\n",
       "               map method2  map method3  NDCG method1  NDCG method2  \\\n",
       "COLLECTIONS       0.631861     0.005157      0.651613      0.736168   \n",
       "CONFIGURATION     0.476717     0.011793      0.565068      0.644081   \n",
       "DATACMNS          0.434572     0.005164      0.565246      0.591686   \n",
       "DATAMONGO         0.409134     0.006628      0.450049      0.579720   \n",
       "DATAREST          0.379916     0.010511      0.496861      0.576070   \n",
       "ELY               0.691837     0.016807      0.673030      0.767301   \n",
       "IO                0.735752     0.020380      0.783384      0.815925   \n",
       "LANG              0.688487     0.008122      0.721918      0.782246   \n",
       "LDAP              0.446406     0.004488      0.491315      0.615002   \n",
       "SEC               0.303046     0.001759      0.511650      0.479949   \n",
       "SOCIALFB          0.343802     0.009881      0.578589      0.543406   \n",
       "SPR               0.196923     0.000683      0.317334      0.390757   \n",
       "\n",
       "               NDCG method3  \n",
       "COLLECTIONS        0.178958  \n",
       "CONFIGURATION      0.221910  \n",
       "DATACMNS           0.179812  \n",
       "DATAMONGO          0.192093  \n",
       "DATAREST           0.216743  \n",
       "ELY                0.242035  \n",
       "IO                 0.254309  \n",
       "LANG               0.197785  \n",
       "LDAP               0.175887  \n",
       "SEC                0.142977  \n",
       "SOCIALFB           0.207597  \n",
       "SPR                0.132376  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "mrr method1     0.492911\n",
       "mrr method2     0.566911\n",
       "mrr method3     0.004319\n",
       "map method1     0.405549\n",
       "map method2     0.478204\n",
       "map method3     0.008448\n",
       "NDCG method1    0.567171\n",
       "NDCG method2    0.626859\n",
       "NDCG method3    0.195207\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scoreBasics(processed_bug_report,processed_source_code, labels, similarities1, similarities2, similarities3):\n",
    "    return {\n",
    "        \"mrr method1\":getMrrValue(labels,similarities1),\n",
    "        \"mrr method2\":getMrrValue(labels,similarities2),\n",
    "        \"mrr method3\":getMrrValue(labels,similarities3),\n",
    "        \"map method1\":getMAPValue(labels,similarities1),\n",
    "        \"map method2\":getMAPValue(labels,similarities2),\n",
    "        \"map method3\":getMAPValue(labels,similarities3),\n",
    "        \"NDCG method1\":getNDCGValue(labels,similarities1),\n",
    "        \"NDCG method2\":getNDCGValue(labels,similarities2),\n",
    "        \"NDCG method3\":getNDCGValue(labels,similarities3),\n",
    "    }\n",
    "basicScores=pd.DataFrame((scoreBasics(*values) for values in project_similarities.values()),index=project_similarities.keys())\n",
    "display(basicScores)\n",
    "\n",
    "averageScores=basicScores.mean()\n",
    "display(averageScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plotting the Data\n",
    "\n",
    "## Graphing NDCG\n",
    "For NDCG, we will look at the trend between the number of recommendations versus the NDCG score. Multiples of 5 for number of recommmendations is used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_k_indices(matrix, k):\n",
    "    #                                 reverse\n",
    "    return np.argsort(matrix)[:,-k:][:,::-1]\n",
    "\n",
    "def scoreTop50IndexesForAllProjects()->Iterable[Dict]:\n",
    "    top_indices_list = range(5,51,5)\n",
    "    for project,(processed_bug_report,processed_source_code, labels, similarities1, similarities2, similarities3) in project_similarities.items():\n",
    "        for method_name,similarity in ((\"method1\",similarities1),(\"method2\",similarities2),(\"method3\",similarities3)):\n",
    "            # score ndcg for every index  in\n",
    "            ndgc={top_index:getNDCGValue(labels,similarity,top_index) for top_index in top_indices_list}\n",
    "            yield {\"project\":project, \"method\":method_name, \"metric\":\"ndgc\", **ndgc}\n",
    "\n",
    "#             map and mrr\n",
    "            indices = get_top_k_indices(similarity, 50)\n",
    "            top_values=np.take_along_axis(similarity, indices,axis=1)\n",
    "            top_labels=np.take_along_axis(labels, indices,axis=1)\n",
    "\n",
    "            mrr={index:getMrrValue(top_labels[:, :index], top_values[:,:index]) for index in top_indices_list}\n",
    "            yield {\"project\":project, \"method\":method_name, \"metric\":\"mrr\", **mrr}\n",
    "\n",
    "            map={index:getMAPValue(top_labels[:, :index], top_values[:,:index]) for index in top_indices_list}\n",
    "            yield {\"project\":project,\"method\":method_name, \"metric\":\"map\", **map}\n",
    "\n",
    "top50Indexes=pd.DataFrame(scoreTop50IndexesForAllProjects())\n",
    "display(top50Indexes)\n",
    "\n",
    "allProjectTop50Indexes=top50Indexes.groupby([\"metric\",\"method\"]).mean()\n",
    "display(allProjectTop50Indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# plt.bar(ndcg_score_df[\"number_recommendations\"],ndcg_score_df[\"method1\"])\n",
    "# plt.xticks(ndcg_score_df[\"number_recommendations\"])\n",
    "# plt.title(\"NDCG Score VS. Number Recommendations\")\n",
    "# plt.xlabel(\"Number Of Recommendations\")\n",
    "# plt.ylabel(\"NDCG Score\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the graph above, the NDGC score increases as the number of recommendations increase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing MRR and MAP\n",
    "\n",
    "As both MRR and MAP are affected by indices, we shall compare the two metrics together. Multiples of 5 for indices are also used to compute the scores for MRR and MAP and are shown in the line graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def getTopIndexesMrrMap():\n",
    "#     mrr_dict,map_dict={\"number_recommendations\":top_indices_list},{\"number_recommendations\":top_indices_list}\n",
    "#\n",
    "#     for methodNumber,similarities in enumerate((similarities1,similarities2,similarities3),1):\n",
    "#         indices = get_top_k_indices(similarities, 50)\n",
    "#         top_values=np.take_along_axis(similarities, indices,axis=1)\n",
    "#         top_labels=np.take_along_axis(labels, indices,axis=1)\n",
    "#         mrr_dict[f\"method{methodNumber}\"] = [getMrrValue(top_labels[:, :index], top_values[:,:index]) for index in top_indices_list]\n",
    "#         map_dict[f\"method{methodNumber}\"] = [getMAPValue(top_labels[:, :index], top_values[:,:index]) for index in top_indices_list]\n",
    "#\n",
    "#     return pd.DataFrame(mrr_dict), pd.DataFrame(map_dict)\n",
    "#\n",
    "# mrr_score_df,map_score_df=getTopIndexesMrrMap()\n",
    "# display(\"mrr\")\n",
    "# display(mrr_score_df)\n",
    "# display(\"map\")\n",
    "# display(map_score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # todo have map and mrr separate\n",
    "# plt.plot(top_indices_list, map_score_df[\"method1\"], label = \"MAP Score For Top Recommendations\")\n",
    "# plt.plot(top_indices_list, mrr_score_df[\"method1\"], label = \"MRR Score For Top Recommendations\")\n",
    "# plt.xlabel('Top K Indices')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title(\"Scores for Top K Indices\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Based on the graph above, MRR performs better than MAP by roughly 10%. Additionally, as the number of indicies increases, the scores also increase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
